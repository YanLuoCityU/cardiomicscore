{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Global Configuration ---\n",
    "\n",
    "# 1. Define file paths\n",
    "BASE_DATA_PATH = \"/your path/cardiomicscore/data/split_seed-250901/\"\n",
    "SCORES_PATH = \"/your path/cardiomicscore/saved/results/Scores/OmicsNet/Final/\"\n",
    "RESULTS_SAVE_DIR = \"/your path/cardiomicscore/saved/results/Survival_Analysis/\"\n",
    "\n",
    "# 2. Define outcomes and scores to be analyzed\n",
    "OUTCOMES_TO_ANALYZE = ['cad', 'stroke', 'hf', 'af', 'pad', 'vte']\n",
    "SCORES_TO_ANALYZE = ['prs', 'metscore', 'proscore']\n",
    "SCORES_TO_STANDARDIZE = ['metscore', 'proscore'] # PRS is typically already standardized\n",
    "\n",
    "# Ensure the results directory exists\n",
    "os.makedirs(RESULTS_SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preparation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(outcome: str):\n",
    "    \"\"\"\n",
    "    Dynamically loads, merges, and preprocesses all necessary data for a specific outcome.\n",
    "    \n",
    "    Args:\n",
    "        outcome (str): The name of the outcome to analyze (e.g., 'af', 'cad').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing all relevant data. Returns an empty DataFrame if critical files are missing.\n",
    "    \"\"\"\n",
    "    print(f\"--- Loading and Preparing Data for Outcome: {outcome.upper()} ---\")\n",
    "    \n",
    "    # 1. Load clinical data\n",
    "    try:\n",
    "        clinical_path = os.path.join(BASE_DATA_PATH, \"X_external_test_PANEL.feather\")\n",
    "        main_df = pd.read_feather(clinical_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Clinical data file not found at {clinical_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 2. Load and merge various scores from consolidated files\n",
    "    score_map = {\n",
    "        'metscore': 'Metabolomics',\n",
    "        'proscore': 'Proteomics'\n",
    "    }\n",
    "    for score_name, score_type in score_map.items():\n",
    "        try:\n",
    "            # Filename is now generic: external_test_scores_{score_type}.csv\n",
    "            score_file = f\"external_test_scores_{score_type}.csv\"\n",
    "            score_path = os.path.join(SCORES_PATH, score_file)\n",
    "            # Read the CSV and select the column corresponding to the current outcome\n",
    "            score_df = pd.read_csv(score_path)[['eid', outcome]].rename(columns={outcome: score_name})\n",
    "            main_df = pd.merge(main_df, score_df, on='eid', how='inner')\n",
    "        except (FileNotFoundError, KeyError) as e:\n",
    "            print(f\"WARNING: Score file '{score_file}' or outcome column '{outcome}' not found. Skipping '{score_name}'. Error: {e}\")\n",
    "\n",
    "    # 3. Load and merge Genomics PRS score (dynamic column name)\n",
    "    try:\n",
    "        genomics_path = os.path.join(BASE_DATA_PATH, \"X_external_test_Genomics.feather\")\n",
    "        prs_col_name = f'{outcome}_prs'\n",
    "        prs_df = pd.read_feather(genomics_path)[['eid', prs_col_name]].rename(columns={prs_col_name: 'prs'})\n",
    "        main_df = pd.merge(main_df, prs_df, on='eid', how='inner')\n",
    "    except (FileNotFoundError, KeyError) as e:\n",
    "        print(f\"WARNING: Genomics file or PRS column '{prs_col_name}' not found. Skipping 'prs'. Error: {e}\")\n",
    "\n",
    "    # 4. Load and merge outcome data from consolidated files (dynamic column names)\n",
    "    try:\n",
    "        y_path = os.path.join(BASE_DATA_PATH, \"y_external_test.feather\")\n",
    "        e_path = os.path.join(BASE_DATA_PATH, \"e_external_test.feather\")\n",
    "        \n",
    "        duration_col = f'bl2{outcome}_yrs'\n",
    "        event_col = outcome\n",
    "        \n",
    "        y_df = pd.read_feather(y_path)[['eid', duration_col]].rename(columns={duration_col: 'duration'})\n",
    "        e_df = pd.read_feather(e_path)[['eid', event_col]].rename(columns={event_col: 'event'})\n",
    "        \n",
    "        main_df = pd.merge(main_df, y_df, on='eid', how='inner')\n",
    "        main_df = pd.merge(main_df, e_df, on='eid', how='inner')\n",
    "    except (FileNotFoundError, KeyError) as e:\n",
    "        print(f\"WARNING: Outcome files for '{outcome}' not found or column missing. Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    # 5. Standardize scores\n",
    "    actual_scores_to_standardize = [col for col in SCORES_TO_STANDARDIZE if col in main_df.columns]\n",
    "    if actual_scores_to_standardize:\n",
    "        scaler = StandardScaler()\n",
    "        main_df[actual_scores_to_standardize] = scaler.fit_transform(main_df[actual_scores_to_standardize])\n",
    "        \n",
    "    print(f\"--- Data for {outcome.upper()} is ready. Shape: {main_df.shape} ---\\n\")\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_event_rate_by_percentile(df: pd.DataFrame, score_columns: list):\n",
    "    \"\"\"Calculates the event rate for each percentile of the given scores.\"\"\"\n",
    "    all_percentile_data = []\n",
    "    for score_col in score_columns:\n",
    "        if score_col not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        score_series = df[score_col]\n",
    "        for j in range(100):\n",
    "            lower_bound = score_series.quantile(j / 100.0)\n",
    "            upper_bound = score_series.quantile((j + 1) / 100.0)\n",
    "            \n",
    "            if j == 99:\n",
    "                subset = df[(score_series >= lower_bound) & (score_series <= upper_bound)]\n",
    "            else:\n",
    "                subset = df[(score_series >= lower_bound) & (score_series < upper_bound)]\n",
    "\n",
    "            n_total = len(subset)\n",
    "            n_events = subset['event'].sum() if n_total > 0 else 0\n",
    "            event_rate = n_events / n_total if n_total > 0 else 0.0\n",
    "            \n",
    "            all_percentile_data.append({\n",
    "                'score_type': score_col,\n",
    "                'percentile': j + 1,\n",
    "                'event_rate': event_rate,\n",
    "                'n_total': n_total,\n",
    "                'n_events': n_events\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(all_percentile_data)\n",
    "\n",
    "def analyze_km_and_logrank(df: pd.DataFrame, score_column: str, outcome: str):\n",
    "    \"\"\"Performs Kaplan-Meier analysis and log-rank test for a given score.\"\"\"\n",
    "    if score_column not in df.columns:\n",
    "        return None, None\n",
    "\n",
    "    # Stratify by score tertiles\n",
    "    try:\n",
    "        low_cutoff = df[score_column].quantile(1/3)\n",
    "        high_cutoff = df[score_column].quantile(2/3)\n",
    "        conditions = [\n",
    "            df[score_column] <= low_cutoff,\n",
    "            (df[score_column] > low_cutoff) & (df[score_column] <= high_cutoff),\n",
    "        ]\n",
    "        choices = [\"Low\", \"Medium\"]\n",
    "        group_col = f'{score_column}_group'\n",
    "        df[group_col] = np.select(conditions, choices, default=\"High\")\n",
    "        \n",
    "        if df[group_col].nunique() < 2:\n",
    "            raise ValueError(\"Stratification resulted in fewer than 2 groups.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Could not stratify {score_column} for outcome {outcome}. Error: {e}.\")\n",
    "        return None, None\n",
    "        \n",
    "    # KM plotting and data preparation\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = plt.subplot(111)\n",
    "    kmf = KaplanMeierFitter()\n",
    "    all_survival_data = []\n",
    "\n",
    "    for name in sorted(df[group_col].unique()):\n",
    "        grouped_df = df[df[group_col] == name]\n",
    "        kmf.fit(grouped_df['duration'], grouped_df['event'], label=f'{name} Risk')\n",
    "        kmf.plot_survival_function(ax=ax)\n",
    "        \n",
    "        survival_df = kmf.confidence_interval_survival_function_.copy()\n",
    "        survival_df['time'] = kmf.survival_function_.index\n",
    "        survival_df['survival_prob'] = kmf.survival_function_.iloc[:, 0]\n",
    "        survival_df['group'] = name\n",
    "        survival_df['score_type'] = score_column\n",
    "        survival_df = survival_df.rename(columns={\n",
    "            f'{kmf.label}_lower_0.95': 'ci_lower',\n",
    "            f'{kmf.label}_upper_0.95': 'ci_upper'\n",
    "        })\n",
    "        all_survival_data.append(survival_df)\n",
    "        \n",
    "    plt.title(f\"Kaplan-Meier Curves for {outcome.upper()} by {score_column.upper()} Group\")\n",
    "    plt.xlabel(\"Time (Years)\")\n",
    "    plt.ylabel(\"Survival Probability\")\n",
    "    plt.ylim(0.8, 1.0)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    km_results_df = pd.concat(all_survival_data, ignore_index=True)\n",
    "        \n",
    "    # Log-Rank Test\n",
    "    groups = df[group_col]\n",
    "    group_labels = sorted(groups.unique())\n",
    "    logrank_results = None\n",
    "    if len(group_labels) == 3:\n",
    "        results_logrank = logrank_test(\n",
    "            durations_A=df.loc[groups == group_labels[0], 'duration'], event_observed_A=df.loc[groups == group_labels[0], 'event'],\n",
    "            durations_B=df.loc[groups == group_labels[1], 'duration'], event_observed_B=df.loc[groups == group_labels[1], 'event'],\n",
    "            durations_C=df.loc[groups == group_labels[2], 'duration'], event_observed_C=df.loc[groups == group_labels[2], 'event']\n",
    "        )\n",
    "        p_value = results_logrank.p_value\n",
    "        if p_value < 0.001:\n",
    "            p_value_formatted = f\"{p_value:.2e}\"  # Scientific notation\n",
    "        else:\n",
    "            p_value_formatted = f\"{p_value:.3f}\"  # 3 decimal places\n",
    "        logrank_results = pd.DataFrame({\n",
    "            'test_statistic': [results_logrank.test_statistic],\n",
    "            'p': [p_value_formatted],\n",
    "            '-log2(p)': [-np.log2(p_value) if p_value > 0 else np.inf]\n",
    "        })\n",
    "        logrank_results['score_type'] = score_column\n",
    "        \n",
    "    return km_results_df, logrank_results\n",
    "\n",
    "def analyze_hazard_ratios(df: pd.DataFrame, score_column: str, all_clinical_vars: list):\n",
    "    \"\"\"\n",
    "    Calculates and saves Hazard Ratios for a given score, analyzed as both a\n",
    "    continuous variable and a categorical (tertile-based) variable.\n",
    "    Includes printing of model details.\n",
    "    \"\"\"\n",
    "    print(f\"===== Analyzing Hazard Ratios for: {score_column.upper()} =====\")\n",
    "\n",
    "    if score_column not in df.columns:\n",
    "        print(f\"Score column '{score_column}' not found. Skipping analysis.\\n\")\n",
    "        return None, None\n",
    "\n",
    "    # --- 1. Analysis with the Score as a CONTINUOUS Variable ---\n",
    "    print(f\"\\n--- Analyzing '{score_column}' as a Continuous Variable ---\")\n",
    "    continuous_results = []\n",
    "    cph_continuous = CoxPHFitter(penalizer=0.03)\n",
    "\n",
    "    # Unadjusted HR\n",
    "    try:\n",
    "        df_unadj = df[[score_column, 'duration', 'event']].dropna()\n",
    "        print(f\"Unadjusted model shape: {df_unadj.shape}\")\n",
    "        cph_continuous.fit(df_unadj, 'duration', 'event', formula=f\"{score_column}\")\n",
    "        hr_unadj = cph_continuous.summary.loc[[score_column]].copy()\n",
    "        hr_unadj['model'] = 'Unadjusted'\n",
    "        continuous_results.append(hr_unadj)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fit unadjusted continuous model for {score_column}: {e}\")\n",
    "\n",
    "    # Adjusted HR for Age & Sex\n",
    "    try:\n",
    "        adj_vars_age_sex = ['age', 'male_1.0']\n",
    "        df_adj_as = df[[score_column] + adj_vars_age_sex + ['duration', 'event']].dropna()\n",
    "        print(f\"Age+Sex adjustment variables: {adj_vars_age_sex}\")\n",
    "        print(f\"Age+Sex adjusted model shape: {df_adj_as.shape}\")\n",
    "        cph_continuous.fit(df_adj_as, 'duration', 'event')\n",
    "        hr_adj_as = cph_continuous.summary.loc[[score_column]].copy()\n",
    "        hr_adj_as['model'] = 'Adjusted (Age+Sex)'\n",
    "        continuous_results.append(hr_adj_as)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fit partially adjusted continuous model for {score_column}: {e}\")\n",
    "\n",
    "    # Adjusted HR for all clinical variables\n",
    "    try:\n",
    "        other_clinical_vars = [v for v in all_clinical_vars if v != score_column]\n",
    "        df_adj_all = df[[score_column] + other_clinical_vars + ['duration', 'event']].dropna()\n",
    "        print(f\"All Clinical adjustment variables: {other_clinical_vars}\")\n",
    "        print(f\"All Clinical adjusted model shape: {df_adj_all.shape}\")\n",
    "        cph_continuous.fit(df_adj_all, 'duration', 'event')\n",
    "        hr_adj_all = cph_continuous.summary.loc[[score_column]].copy()\n",
    "        hr_adj_all['model'] = 'Adjusted (All Clinical)'\n",
    "        continuous_results.append(hr_adj_all)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fit fully adjusted continuous model for {score_column}: {e}\")\n",
    "\n",
    "    continuous_results_df = pd.concat(continuous_results).reset_index().rename(columns={'index': 'covariate'})\n",
    "    continuous_results_df['score_type'] = score_column\n",
    "\n",
    "    # --- 2. Analysis with the Score as a CATEGORICAL Variable (Tertiles) ---\n",
    "    print(f\"\\n--- Analyzing '{score_column}' as a Categorical (Tertile) Variable ---\")\n",
    "    categorical_results = []\n",
    "    cph_categorical = CoxPHFitter(penalizer=0.01)\n",
    "\n",
    "    # Create the categorical group column\n",
    "    try:\n",
    "        low_cutoff = df[score_column].quantile(1/3)\n",
    "        high_cutoff = df[score_column].quantile(2/3)\n",
    "        risk_categories = [\"Low\", \"Medium\", \"High\"]\n",
    "        group_col = f'{score_column}_group'\n",
    "        df[group_col] = pd.cut(df[score_column], bins=[-np.inf, low_cutoff, high_cutoff, np.inf], labels=risk_categories)\n",
    "        df[group_col] = pd.Categorical(df[group_col], categories=risk_categories, ordered=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not stratify {score_column}. Skipping categorical analysis. Error: {e}\")\n",
    "        return continuous_results_df, None\n",
    "    \n",
    "    # Define the score group columns to keep in the final output\n",
    "    score_group_columns = [f'{score_column}_group_Medium', f'{score_column}_group_High']\n",
    "\n",
    "    # Unadjusted HR for categories\n",
    "    try:\n",
    "        df_cat_unadj = pd.get_dummies(df[[group_col, 'duration', 'event']].dropna(), columns=[group_col], drop_first=True)\n",
    "        cph_categorical.fit(df_cat_unadj, 'duration', 'event')\n",
    "        summary_unadj = cph_categorical.summary.loc[score_group_columns].copy()\n",
    "        summary_unadj['model'] = 'Unadjusted'\n",
    "        categorical_results.append(summary_unadj)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fit unadjusted categorical model for {score_column}: {e}\")\n",
    "\n",
    "    # Adjusted HR for Age & Sex for categories\n",
    "    try:\n",
    "        df_cat_adj_as = pd.get_dummies(df[[group_col] + adj_vars_age_sex + ['duration', 'event']].dropna(), columns=[group_col], drop_first=True)\n",
    "        cph_categorical.fit(df_cat_adj_as, 'duration', 'event')\n",
    "        summary_adj_as = cph_categorical.summary.loc[score_group_columns].copy()\n",
    "        summary_adj_as['model'] = 'Adjusted (Age+Sex)'\n",
    "        categorical_results.append(summary_adj_as)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fit partially adjusted categorical model for {score_column}: {e}\")\n",
    "\n",
    "    # Adjusted HR for all clinical variables for categories\n",
    "    try:\n",
    "        df_cat_adj_all = pd.get_dummies(df[[group_col] + all_clinical_vars + ['duration', 'event']].dropna(), columns=[group_col], drop_first=True)\n",
    "        cph_categorical.fit(df_cat_adj_all, 'duration', 'event')\n",
    "        summary_adj_all = cph_categorical.summary.loc[score_group_columns].copy()\n",
    "        summary_adj_all['model'] = 'Adjusted (All Clinical)'\n",
    "        categorical_results.append(summary_adj_all)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fit fully adjusted categorical model for {score_column}: {e}\")\n",
    "\n",
    "    categorical_results_df = pd.concat(categorical_results).reset_index().rename(columns={'index': 'covariate'})\n",
    "    categorical_results_df['score_type'] = score_column\n",
    "\n",
    "    print(f\"===== Finished Hazard Ratio Analysis for: {score_column.upper()} =====\\n\")\n",
    "    \n",
    "    return continuous_results_df, categorical_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Execution Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution Loop ---\n",
    "\n",
    "# Initialize lists to store results from all outcomes\n",
    "all_event_rates_list = []\n",
    "all_km_data_list = []\n",
    "all_logrank_list = []\n",
    "all_hr_continuous_list = []\n",
    "all_hr_categorical_list = []\n",
    "\n",
    "# Get the list of all clinical variables once\n",
    "try:\n",
    "    clinical_path = os.path.join(BASE_DATA_PATH, \"X_external_test_PANEL.feather\")\n",
    "    base_clinical_vars = [col for col in pd.read_feather(clinical_path).columns if col != 'eid']\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: X_external_test_Clinical.feather not found. Using minimal adjustment vars.\")\n",
    "    base_clinical_vars = ['age', 'male_1.0']\n",
    "\n",
    "# Loop through each outcome\n",
    "for outcome in OUTCOMES_TO_ANALYZE:\n",
    "    master_df = load_and_prepare_data(outcome)\n",
    "    \n",
    "    if master_df.empty:\n",
    "        print(f\"Skipping analysis for outcome {outcome} due to missing data.\")\n",
    "        continue\n",
    "    \n",
    "    # --- 1. Event Rate Analysis ---\n",
    "    print(f\"Calculating event rates for {outcome.upper()}...\")\n",
    "    event_rate_df = calculate_event_rate_by_percentile(master_df, SCORES_TO_ANALYZE)\n",
    "    event_rate_df['outcome'] = outcome\n",
    "    all_event_rates_list.append(event_rate_df)\n",
    "    \n",
    "    # --- 2. KM and Log-rank Analysis ---\n",
    "    print(f\"Performing Kaplan-Meier analysis for {outcome.upper()}...\")\n",
    "    for score in SCORES_TO_ANALYZE:\n",
    "        km_df, logrank_df = analyze_km_and_logrank(master_df.copy(), score, outcome)\n",
    "        if km_df is not None:\n",
    "            km_df['outcome'] = outcome\n",
    "            all_km_data_list.append(km_df)\n",
    "        if logrank_df is not None:\n",
    "            logrank_df['outcome'] = outcome\n",
    "            all_logrank_list.append(logrank_df)\n",
    "            \n",
    "    # --- 3. Hazard Ratio Analysis ---\n",
    "    print(f\"Calculating Hazard Ratios for {outcome.upper()}...\")\n",
    "    for score in SCORES_TO_ANALYZE:\n",
    "        adjustment_vars = [var for var in base_clinical_vars if var != score]\n",
    "        hr_cont_df, hr_cat_df = analyze_hazard_ratios(master_df.copy(), score, adjustment_vars)\n",
    "        if hr_cont_df is not None:\n",
    "            hr_cont_df['outcome'] = outcome\n",
    "            all_hr_continuous_list.append(hr_cont_df)\n",
    "        if hr_cat_df is not None:\n",
    "            hr_cat_df['outcome'] = outcome\n",
    "            all_hr_categorical_list.append(hr_cat_df)\n",
    "\n",
    "print(\"\\n--- All analyses complete. Aggregating and saving results. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Aggregation and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Observed Event Rates\n",
    "if all_event_rates_list:\n",
    "    final_event_rates = pd.concat(all_event_rates_list, ignore_index=True)\n",
    "    save_path = os.path.join(RESULTS_SAVE_DIR, \"summary_observed_event_rate.csv\")\n",
    "    final_event_rates.to_csv(save_path, index=False, float_format='%.6f')\n",
    "    print(f\"\\nSaved combined event rate data to: {save_path}\")\n",
    "    print(\"Event Rate Data Preview:\")\n",
    "    print(final_event_rates.head())\n",
    "\n",
    "# 2. KM Data\n",
    "if all_km_data_list:\n",
    "    final_km_data = pd.concat(all_km_data_list, ignore_index=True)\n",
    "    save_path = os.path.join(RESULTS_SAVE_DIR, \"summary_survival_km_data.csv\")\n",
    "    final_km_data.to_csv(save_path, index=False, float_format='%.6f')\n",
    "    print(f\"\\nSaved combined KM survival data to: {save_path}\")\n",
    "\n",
    "# 3. Log-rank Results\n",
    "if all_logrank_list:\n",
    "    final_logrank_data = pd.concat(all_logrank_list, ignore_index=True)\n",
    "    save_path = os.path.join(RESULTS_SAVE_DIR, \"summary_logrank_test_results.csv\")\n",
    "    final_logrank_data.to_csv(save_path, index=False, float_format='%.4f')\n",
    "    print(f\"\\nSaved combined Log-rank test results to: {save_path}\")\n",
    "\n",
    "# 4. Continuous HR Results\n",
    "if all_hr_continuous_list:\n",
    "    final_hr_continuous = pd.concat(all_hr_continuous_list, ignore_index=True)\n",
    "    save_path = os.path.join(RESULTS_SAVE_DIR, \"summary_hazard_ratio_continuous.csv\")\n",
    "    final_hr_continuous.to_csv(save_path, index=False, float_format='%.4f')\n",
    "    print(f\"\\nSaved combined continuous HR results to: {save_path}\")\n",
    "\n",
    "# 5. Categorical HR Results\n",
    "if all_hr_categorical_list:\n",
    "    final_hr_categorical = pd.concat(all_hr_categorical_list, ignore_index=True)\n",
    "    save_path = os.path.join(RESULTS_SAVE_DIR, \"summary_hazard_ratio_categorical.csv\")\n",
    "    final_hr_categorical.to_csv(save_path, index=False, float_format='%.4f')\n",
    "    print(f\"\\nSaved combined categorical HR results to: {save_path}\")\n",
    "\n",
    "print(\"\\n--- Script finished successfully! ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omicscvd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
