{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Set File Paths ---\n",
    "base_path = '/your path/cardiomicscore/saved/results/Cindex'\n",
    "summary_file = os.path.join(base_path, 'cindex_summary.csv')\n",
    "ci_file = os.path.join(base_path, 'cindex_bootstrap_ci_summary.csv')\n",
    "output_dir = '/your path/cardiomicscore/saved/results/Cindex/Merge'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, 'cindex_final.csv')\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    summary_df = pd.read_csv(summary_file)\n",
    "    ci_df = pd.read_csv(ci_file)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found. Please check if the path is correct. {e}\")\n",
    "    exit() # Exit the script if files are not found\n",
    "\n",
    "# --- 3. Merge Data ---\n",
    "merge_keys = ['outcome', 'baseline_model', 'comparison_model', 'n_samples']\n",
    "ci_cols_to_merge = merge_keys + [\n",
    "    'c_index_combo_ci_lower', 'c_index_combo_ci_upper',\n",
    "    'delta_c_index_ci_lower', 'delta_c_index_ci_upper'\n",
    "]\n",
    "print(\"Merging the two DataFrames...\")\n",
    "merged_df = pd.merge(summary_df, ci_df[ci_cols_to_merge], on=merge_keys, how='inner')\n",
    "print(\"Data merge complete.\")\n",
    "\n",
    "\n",
    "# --- 4. Reshape Data ---\n",
    "print(\"Reshaping data into a long format...\")\n",
    "# Part A: Create the c_index part\n",
    "c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'c_index_combo', 'c_index_combo_ci_lower', 'c_index_combo_ci_upper']].copy()\n",
    "c_index_part['metric'] = 'c_index'\n",
    "c_index_part.rename(columns={\n",
    "    'c_index_combo': 'point_estimate',\n",
    "    'c_index_combo_ci_lower': 'ci_lower',\n",
    "    'c_index_combo_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# Part B: Create the delta_c_index part\n",
    "delta_c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'delta_c_index', 'delta_c_index_ci_lower', 'delta_c_index_ci_upper']].copy()\n",
    "delta_c_index_part['metric'] = 'delta_c_index'\n",
    "delta_c_index_part.rename(columns={\n",
    "    'delta_c_index': 'point_estimate',\n",
    "    'delta_c_index_ci_lower': 'ci_lower',\n",
    "    'delta_c_index_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# --- 5. Final Integration ---\n",
    "final_df = pd.concat([c_index_part, delta_c_index_part], ignore_index=True)\n",
    "final_df = final_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'metric', 'point_estimate', 'ci_lower', 'ci_upper']]\n",
    "print(\"Data reshaping complete.\")\n",
    "\n",
    "# --- 6. Save Results ---\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nProcessing complete! The consolidated file has been saved to:\\n{output_file}\")\n",
    "\n",
    "# --- Print a preview of the result ---\n",
    "print(\"\\nFinal Data Preview (first 10 rows):\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Set File Paths ---\n",
    "base_path = '/your path/cardiomicscore/saved/results/Cindex'\n",
    "output_dir = '/your path/cardiomicscore/saved/results/Cindex/Merge'\n",
    "summary_file = os.path.join(base_path, 'cindex_subgroup_summary.csv')\n",
    "\n",
    "# List of all Confidence Interval (CI) files to be consolidated\n",
    "ci_files = [\n",
    "    'cindex_subgroup_bootstrap_ci_Age.csv',\n",
    "    'cindex_subgroup_bootstrap_ci_Sex.csv',\n",
    "    'cindex_subgroup_bootstrap_ci_Lipid.csv',\n",
    "    'cindex_subgroup_bootstrap_ci_Antihypertensive.csv'\n",
    "]\n",
    "\n",
    "# Full path for the final output file\n",
    "output_file = os.path.join(output_dir, 'cindex_subgroup_final.csv')\n",
    "\n",
    "\n",
    "# --- 2. Load and consolidate all CI files ---\n",
    "print(\"Loading and consolidating all subgroup CI files...\")\n",
    "ci_df_list = []\n",
    "try:\n",
    "    for file_name in ci_files:\n",
    "        full_path = os.path.join(base_path, file_name)\n",
    "        df = pd.read_csv(full_path)\n",
    "        ci_df_list.append(df)\n",
    "    combined_ci_df = pd.concat(ci_df_list, ignore_index=True)\n",
    "    print(f\"Successfully consolidated {len(ci_files)} CI files.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found. Please check the CI file list and paths. {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Load main data file and merge ---\n",
    "print(\"Loading the main summary file...\")\n",
    "try:\n",
    "    summary_df = pd.read_csv(summary_file)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find the summary file {summary_file}.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Merging the summary data with the CI data...\")\n",
    "merge_keys = ['subgroup', 'outcome', 'baseline_model', 'comparison_model', 'n_samples']\n",
    "ci_cols_to_merge = merge_keys + [\n",
    "    'c_index_combo_ci_lower', 'c_index_combo_ci_upper',\n",
    "    'delta_c_index_ci_lower', 'delta_c_index_ci_upper'\n",
    "]\n",
    "\n",
    "# Perform the merge operation\n",
    "merged_df = pd.merge(summary_df, combined_ci_df[ci_cols_to_merge], on=merge_keys, how='inner')\n",
    "print(\"Data merge complete.\")\n",
    "\n",
    "\n",
    "# --- 4. Reshape Data (same logic as before) ---\n",
    "print(\"Reshaping data into a long format...\")\n",
    "\n",
    "# Part A: c_index part\n",
    "c_index_cols = merge_keys + ['c_index_combo', 'c_index_combo_ci_lower', 'c_index_combo_ci_upper']\n",
    "c_index_part = merged_df[c_index_cols].copy()\n",
    "c_index_part['metric'] = 'c_index'\n",
    "c_index_part.rename(columns={\n",
    "    'c_index_combo': 'point_estimate',\n",
    "    'c_index_combo_ci_lower': 'ci_lower',\n",
    "    'c_index_combo_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "# Part B: delta_c_index part\n",
    "delta_c_index_cols = merge_keys + ['delta_c_index', 'delta_c_index_ci_lower', 'delta_c_index_ci_upper']\n",
    "delta_c_index_part = merged_df[delta_c_index_cols].copy()\n",
    "delta_c_index_part['metric'] = 'delta_c_index'\n",
    "delta_c_index_part.rename(columns={\n",
    "    'delta_c_index': 'point_estimate',\n",
    "    'delta_c_index_ci_lower': 'ci_lower',\n",
    "    'delta_c_index_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "# --- 5. Final Integration ---\n",
    "final_df = pd.concat([c_index_part, delta_c_index_part], ignore_index=True)\n",
    "output_columns = [\n",
    "    'subgroup', 'outcome', 'n_samples', 'baseline_model', \n",
    "    'comparison_model', 'metric', 'point_estimate', 'ci_lower', 'ci_upper'\n",
    "]\n",
    "final_df = final_df[output_columns]\n",
    "print(\"Data reshaping complete.\")\n",
    "\n",
    "\n",
    "# --- 6. Save Results ---\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nProcessing complete! The consolidated file has been saved to:\\n{output_file}\")\n",
    "\n",
    "# --- Print a preview of the result ---\n",
    "print(\"\\nFinal Data Preview (first 10 rows):\")\n",
    "print(final_df.head(10))\n",
    "print(\"\\nFinal Data Preview (last 10 rows):\")\n",
    "print(final_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual biomarker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Set File Paths ---\n",
    "base_path = '/your path/cardiomicscore/saved/results/Cindex'\n",
    "output_dir = '/your path/cardiomicscore/saved/results/Cindex/Merge'\n",
    "output_file = os.path.join(output_dir, 'cindex_individual_biomarker_final.csv')\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "summary_file = os.path.join(base_path, 'cindex_individual_biomarker_summary.csv')\n",
    "ci_files_list = [\n",
    "    'cindex_individual_biomarker_protein_bootstrap_ci_summary.csv',\n",
    "    'cindex_individual_biomarker_metabolite_bootstrap_ci_summary.csv'\n",
    "]\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    summary_df = pd.read_csv(summary_file)\n",
    "    \n",
    "    ci_df_list = []\n",
    "    for file_name in ci_files_list:\n",
    "        full_path = os.path.join(base_path, file_name)\n",
    "        print(f\"Loading CI file: {file_name}\")\n",
    "        df = pd.read_csv(full_path)\n",
    "        \n",
    "        if 'protein' in file_name:\n",
    "            df['biomarker'] = 'protein'\n",
    "        elif 'metabolite' in file_name:\n",
    "            df['biomarker'] = 'metabolite'\n",
    "        else:\n",
    "            df['biomarker'] = 'unknown' # Add a fallback value\n",
    "            \n",
    "        ci_df_list.append(df)\n",
    "        \n",
    "    combined_ci_df = pd.concat(ci_df_list, ignore_index=True)\n",
    "    \n",
    "    print(\"Data loaded successfully!\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found. Please check if the path is correct. {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Merge Data ---\n",
    "merge_keys = ['outcome', 'baseline_model', 'comparison_model', 'n_samples']\n",
    "ci_cols_to_merge = merge_keys + [\n",
    "    'c_index_combo_ci_lower', 'c_index_combo_ci_upper',\n",
    "    'delta_c_index_ci_lower', 'delta_c_index_ci_upper',\n",
    "    'biomarker'\n",
    "]\n",
    "print(\"Merging the two DataFrames...\")\n",
    "merged_df = pd.merge(summary_df, combined_ci_df[ci_cols_to_merge], on=merge_keys, how='inner')\n",
    "print(\"Data merge complete.\")\n",
    "\n",
    "\n",
    "# --- 4. Reshape Data ---\n",
    "print(\"Reshaping data into a long format...\")\n",
    "cols_to_keep = ['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'biomarker']\n",
    "\n",
    "# Part A: Create the c_index part\n",
    "c_index_part = merged_df[cols_to_keep + ['c_index_combo', 'c_index_combo_ci_lower', 'c_index_combo_ci_upper']].copy()\n",
    "c_index_part['metric'] = 'c_index'\n",
    "c_index_part.rename(columns={\n",
    "    'c_index_combo': 'point_estimate',\n",
    "    'c_index_combo_ci_lower': 'ci_lower',\n",
    "    'c_index_combo_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# Part B: Create the delta_c_index part\n",
    "delta_c_index_part = merged_df[cols_to_keep + ['delta_c_index', 'delta_c_index_ci_lower', 'delta_c_index_ci_upper']].copy()\n",
    "delta_c_index_part['metric'] = 'delta_c_index'\n",
    "delta_c_index_part.rename(columns={\n",
    "    'delta_c_index': 'point_estimate',\n",
    "    'delta_c_index_ci_lower': 'ci_lower',\n",
    "    'delta_c_index_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# --- 5. Final Integration ---\n",
    "final_df = pd.concat([c_index_part, delta_c_index_part], ignore_index=True)\n",
    "final_df = final_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'biomarker', 'metric', 'point_estimate', 'ci_lower', 'ci_upper']]\n",
    "print(\"Data reshaping complete.\")\n",
    "\n",
    "# --- 6. Save Results ---\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nProcessing complete! The consolidated file has been saved to:\\n{output_file}\")\n",
    "\n",
    "# --- Print a preview of the result ---\n",
    "print(\"\\nFinal Data Preview (first 10 rows):\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDL biomarker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Set File Paths ---\n",
    "base_path = '/your path/cardiomicscore/saved/results/Cindex'\n",
    "summary_file = os.path.join(base_path, 'cindex_LDL_biomarker_summary.csv')\n",
    "ci_file = os.path.join(base_path, 'cindex_LDL_biomarker_bootstrap_ci_summary.csv')\n",
    "output_dir = '/your path/cardiomicscore/saved/results/Cindex/Merge'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, 'cindex_LDL_biomarker_final.csv')\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    summary_df = pd.read_csv(summary_file)\n",
    "    ci_df = pd.read_csv(ci_file)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found. Please check if the path is correct. {e}\")\n",
    "    exit() # Exit the script if files are not found\n",
    "\n",
    "# --- 3. Merge Data ---\n",
    "merge_keys = ['outcome', 'baseline_model', 'comparison_model', 'n_samples']\n",
    "ci_cols_to_merge = merge_keys + [\n",
    "    'c_index_combo_ci_lower', 'c_index_combo_ci_upper',\n",
    "    'delta_c_index_ci_lower', 'delta_c_index_ci_upper'\n",
    "]\n",
    "print(\"Merging the two DataFrames...\")\n",
    "merged_df = pd.merge(summary_df, ci_df[ci_cols_to_merge], on=merge_keys, how='inner')\n",
    "print(\"Data merge complete.\")\n",
    "\n",
    "\n",
    "# --- 4. Reshape Data ---\n",
    "print(\"Reshaping data into a long format...\")\n",
    "# Part A: Create the c_index part\n",
    "c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'c_index_combo', 'c_index_combo_ci_lower', 'c_index_combo_ci_upper']].copy()\n",
    "c_index_part['metric'] = 'c_index'\n",
    "c_index_part.rename(columns={\n",
    "    'c_index_combo': 'point_estimate',\n",
    "    'c_index_combo_ci_lower': 'ci_lower',\n",
    "    'c_index_combo_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# Part B: Create the delta_c_index part\n",
    "delta_c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'delta_c_index', 'delta_c_index_ci_lower', 'delta_c_index_ci_upper']].copy()\n",
    "delta_c_index_part['metric'] = 'delta_c_index'\n",
    "delta_c_index_part.rename(columns={\n",
    "    'delta_c_index': 'point_estimate',\n",
    "    'delta_c_index_ci_lower': 'ci_lower',\n",
    "    'delta_c_index_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# --- 5. Final Integration ---\n",
    "final_df = pd.concat([c_index_part, delta_c_index_part], ignore_index=True)\n",
    "final_df = final_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'metric', 'point_estimate', 'ci_lower', 'ci_upper']]\n",
    "print(\"Data reshaping complete.\")\n",
    "\n",
    "# --- 6. Save Results ---\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nProcessing complete! The consolidated file has been saved to:\\n{output_file}\")\n",
    "\n",
    "# --- Print a preview of the result ---\n",
    "print(\"\\nFinal Data Preview (first 10 rows):\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No statins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Set File Paths ---\n",
    "base_path = '/your path/cardiomicscore/saved/results/Cindex'\n",
    "summary_file = os.path.join(base_path, 'cindex_LDL_biomarker_no_statins_summary.csv')\n",
    "ci_file = os.path.join(base_path, 'cindex_LDL_biomarker_no_statins_bootstrap_ci_summary.csv')\n",
    "output_dir = '/your path/cardiomicscore/saved/results/Cindex/Merge'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, 'cindex_LDL_biomarker_no_statins_final.csv')\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    summary_df = pd.read_csv(summary_file)\n",
    "    ci_df = pd.read_csv(ci_file)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found. Please check if the path is correct. {e}\")\n",
    "    exit() # Exit the script if files are not found\n",
    "\n",
    "# --- 3. Merge Data ---\n",
    "merge_keys = ['outcome', 'baseline_model', 'comparison_model', 'n_samples']\n",
    "ci_cols_to_merge = merge_keys + [\n",
    "    'c_index_combo_ci_lower', 'c_index_combo_ci_upper',\n",
    "    'delta_c_index_ci_lower', 'delta_c_index_ci_upper'\n",
    "]\n",
    "print(\"Merging the two DataFrames...\")\n",
    "merged_df = pd.merge(summary_df, ci_df[ci_cols_to_merge], on=merge_keys, how='inner')\n",
    "print(\"Data merge complete.\")\n",
    "\n",
    "\n",
    "# --- 4. Reshape Data ---\n",
    "print(\"Reshaping data into a long format...\")\n",
    "# Part A: Create the c_index part\n",
    "c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'c_index_combo', 'c_index_combo_ci_lower', 'c_index_combo_ci_upper']].copy()\n",
    "c_index_part['metric'] = 'c_index'\n",
    "c_index_part.rename(columns={\n",
    "    'c_index_combo': 'point_estimate',\n",
    "    'c_index_combo_ci_lower': 'ci_lower',\n",
    "    'c_index_combo_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# Part B: Create the delta_c_index part\n",
    "delta_c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'delta_c_index', 'delta_c_index_ci_lower', 'delta_c_index_ci_upper']].copy()\n",
    "delta_c_index_part['metric'] = 'delta_c_index'\n",
    "delta_c_index_part.rename(columns={\n",
    "    'delta_c_index': 'point_estimate',\n",
    "    'delta_c_index_ci_lower': 'ci_lower',\n",
    "    'delta_c_index_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# --- 5. Final Integration ---\n",
    "final_df = pd.concat([c_index_part, delta_c_index_part], ignore_index=True)\n",
    "final_df = final_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'metric', 'point_estimate', 'ci_lower', 'ci_upper']]\n",
    "print(\"Data reshaping complete.\")\n",
    "\n",
    "# --- 6. Save Results ---\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nProcessing complete! The consolidated file has been saved to:\\n{output_file}\")\n",
    "\n",
    "# --- Print a preview of the result ---\n",
    "print(\"\\nFinal Data Preview (first 10 rows):\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# =============================================================================\n",
    "#  Setup Common Paths\n",
    "# =============================================================================\n",
    "base_path = '/your path/cardiomicscore/saved/results/Cindex'\n",
    "output_dir = '/your path/cardiomicscore/saved/results/Cindex/Merge'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# =============================================================================\n",
    "#  Part 1: Process the 'biomarker' files in memory\n",
    "# =============================================================================\n",
    "print(\"--- Starting Part 1: Processing 'biomarker' data ---\")\n",
    "\n",
    "# --- 1.1 Set File Paths for biomarker data ---\n",
    "summary_file = os.path.join(base_path, 'cindex_LDL_biomarker_no_statins_summary.csv')\n",
    "ci_file = os.path.join(base_path, 'cindex_LDL_biomarker_no_statins_bootstrap_ci_summary.csv')\n",
    "\n",
    "# --- 1.2 Load Data for biomarker ---\n",
    "print(\"Loading biomarker data...\")\n",
    "try:\n",
    "    summary_df = pd.read_csv(summary_file)\n",
    "    ci_df = pd.read_csv(ci_file)\n",
    "    print(\"Biomarker data loaded successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Biomarker file not found. {e}\")\n",
    "\n",
    "# --- 1.3 Merge and Reshape Data for biomarker ---\n",
    "if 'summary_df' in locals() and 'ci_df' in locals():\n",
    "    merge_keys = ['outcome', 'baseline_model', 'comparison_model', 'n_samples']\n",
    "    ci_cols_to_merge = merge_keys + [\n",
    "        'c_index_combo_ci_lower', 'c_index_combo_ci_upper',\n",
    "        'delta_c_index_ci_lower', 'delta_c_index_ci_upper'\n",
    "    ]\n",
    "    merged_df = pd.merge(summary_df, ci_df[ci_cols_to_merge], on=merge_keys, how='inner')\n",
    "\n",
    "    c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'c_index_combo', 'c_index_combo_ci_lower', 'c_index_combo_ci_upper']].copy()\n",
    "    c_index_part['metric'] = 'c_index'\n",
    "    c_index_part.rename(columns={\n",
    "        'c_index_combo': 'point_estimate',\n",
    "        'c_index_combo_ci_lower': 'ci_lower',\n",
    "        'c_index_combo_ci_upper': 'ci_upper'\n",
    "    }, inplace=True)\n",
    "\n",
    "    delta_c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'delta_c_index', 'delta_c_index_ci_lower', 'delta_c_index_ci_upper']].copy()\n",
    "    delta_c_index_part['metric'] = 'delta_c_index'\n",
    "    delta_c_index_part.rename(columns={\n",
    "        'delta_c_index': 'point_estimate',\n",
    "        'delta_c_index_ci_lower': 'ci_lower',\n",
    "        'delta_c_index_ci_upper': 'ci_upper'\n",
    "    }, inplace=True)\n",
    "\n",
    "    final_df = pd.concat([c_index_part, delta_c_index_part], ignore_index=True)\n",
    "    final_df = final_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'metric', 'point_estimate', 'ci_lower', 'ci_upper']]\n",
    "    print(\"Biomarker data processed and held in memory.\")\n",
    "\n",
    "print(\"\\n--- Finished Part 1 ---\\n\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "#  Part 2: Process the 'panel' files in memory\n",
    "# =============================================================================\n",
    "print(\"--- Starting Part 2: Processing 'panel' data ---\")\n",
    "\n",
    "# --- 2.1 Set File Paths for panel data ---\n",
    "summary_file_panel = os.path.join(base_path, 'cindex_LDL_biomarker_no_statins_panel_summary.csv')\n",
    "ci_file_panel = os.path.join(base_path, 'cindex_LDL_biomarker_no_statins_panel_bootstrap_ci_summary.csv')\n",
    "\n",
    "# --- 2.2 Load Data for panel ---\n",
    "print(\"Loading panel data...\")\n",
    "try:\n",
    "    summary_df_panel = pd.read_csv(summary_file_panel)\n",
    "    ci_df_panel = pd.read_csv(ci_file_panel)\n",
    "    print(\"Panel data loaded successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Panel file not found. {e}\")\n",
    "\n",
    "# --- 2.3 Merge and Reshape Data for panel ---\n",
    "if 'summary_df_panel' in locals() and 'ci_df_panel' in locals():\n",
    "    merge_keys_panel = ['outcome', 'baseline_model', 'comparison_model', 'n_samples']\n",
    "    ci_cols_to_merge_panel = merge_keys_panel + [\n",
    "        'c_index_combo_ci_lower', 'c_index_combo_ci_upper',\n",
    "        'delta_c_index_ci_lower', 'delta_c_index_ci_upper'\n",
    "    ]\n",
    "    merged_df_panel = pd.merge(summary_df_panel, ci_df_panel[ci_cols_to_merge_panel], on=merge_keys_panel, how='inner')\n",
    "\n",
    "    c_index_part_panel = merged_df_panel[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'c_index_combo', 'c_index_combo_ci_lower', 'c_index_combo_ci_upper']].copy()\n",
    "    c_index_part_panel['metric'] = 'c_index'\n",
    "    c_index_part_panel.rename(columns={\n",
    "        'c_index_combo': 'point_estimate',\n",
    "        'c_index_combo_ci_lower': 'ci_lower',\n",
    "        'c_index_combo_ci_upper': 'ci_upper'\n",
    "    }, inplace=True)\n",
    "\n",
    "    delta_c_index_part_panel = merged_df_panel[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'delta_c_index', 'delta_c_index_ci_lower', 'delta_c_index_ci_upper']].copy()\n",
    "    delta_c_index_part_panel['metric'] = 'delta_c_index'\n",
    "    delta_c_index_part_panel.rename(columns={\n",
    "        'delta_c_index': 'point_estimate',\n",
    "        'delta_c_index_ci_lower': 'ci_lower',\n",
    "        'delta_c_index_ci_upper': 'ci_upper'\n",
    "    }, inplace=True)\n",
    "\n",
    "    final_df_panel = pd.concat([c_index_part_panel, delta_c_index_part_panel], ignore_index=True)\n",
    "    final_df_panel = final_df_panel[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'metric', 'point_estimate', 'ci_lower', 'ci_upper']]\n",
    "    print(\"Panel data processed and held in memory.\")\n",
    "\n",
    "print(\"\\n--- Finished Part 2 ---\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "#  Part 3: Combine results and save the single final file\n",
    "# =============================================================================\n",
    "print(\"\\n--- Starting Part 3: Combining and saving final result ---\")\n",
    "\n",
    "# Create a list to hold the dataframes we want to combine\n",
    "dfs_to_combine = []\n",
    "if 'final_df' in locals():\n",
    "    dfs_to_combine.append(final_df)\n",
    "if 'final_df_panel' in locals():\n",
    "    dfs_to_combine.append(final_df_panel)\n",
    "\n",
    "# Proceed only if there is at least one dataframe to combine\n",
    "if dfs_to_combine:\n",
    "    # Concatenate all dataframes in the list\n",
    "    combined_df = pd.concat(dfs_to_combine, ignore_index=True)\n",
    "\n",
    "    # Define the final output file path and save the result\n",
    "    final_output_file = os.path.join(output_dir, 'cindex_LDL_biomarker_no_statins_final.csv')\n",
    "    combined_df.to_csv(final_output_file, index=False)\n",
    "\n",
    "    print(f\"\\nSuccessfully combined {len(dfs_to_combine)} result set(s).\")\n",
    "    print(f\"Final file saved to:\\n{final_output_file}\")\n",
    "\n",
    "    print(\"\\nFinal Combined Data Preview (first 10 rows):\")\n",
    "    print(combined_df.head(10))\n",
    "else:\n",
    "    print(\"\\nNo dataframes were created, so no final file was generated.\")\n",
    "\n",
    "print(\"\\n--- Script finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_and_merge_cindex_data(model_prefix, base_path, output_dir):\n",
    "    \"\"\"\n",
    "    A general function to load, merge, format, and save C-index data for a specific model.\n",
    "\n",
    "    Args:\n",
    "        model_prefix (str): The prefix name of the model, e.g., 'glm', 'xgb'.\n",
    "        base_path (str): The directory where the input files are located.\n",
    "        output_dir (str): The directory where the output file will be saved.\n",
    "    \"\"\"\n",
    "    # --- 1. Dynamically generate filenames based on the model prefix ---\n",
    "    summary_file = os.path.join(base_path, f'cindex_{model_prefix}_summary.csv')\n",
    "    ci_file = os.path.join(base_path, f'cindex_{model_prefix}_bootstrap_ci_summary.csv')\n",
    "    output_file = os.path.join(output_dir, f'cindex_{model_prefix}_final.csv')\n",
    "\n",
    "    print(f\"--- Processing model: {model_prefix} ---\")\n",
    "\n",
    "    # --- 2. Load Data ---\n",
    "    try:\n",
    "        summary_df = pd.read_csv(summary_file)\n",
    "        ci_df = pd.read_csv(ci_file)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading files for {model_prefix}. Skipping. Details: {e}\")\n",
    "        return # If files don't exist, skip this model and return from the function\n",
    "\n",
    "    # --- 3. Merge Data ---\n",
    "    merge_keys = ['outcome', 'baseline_model', 'comparison_model', 'n_samples']\n",
    "    ci_cols_to_merge = merge_keys + [\n",
    "        'c_index_combo_ci_lower', 'c_index_combo_ci_upper',\n",
    "        'delta_c_index_ci_lower', 'delta_c_index_ci_upper'\n",
    "    ]\n",
    "    merged_df = pd.merge(summary_df, ci_df[ci_cols_to_merge], on=merge_keys, how='inner')\n",
    "\n",
    "    # --- 4. Reshape Data (Logic is the same as in your original script) ---\n",
    "    # Part A: Create the c_index part\n",
    "    c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'c_index_combo', 'c_index_combo_ci_lower', 'c_index_combo_ci_upper']].copy()\n",
    "    c_index_part['metric'] = 'c_index'\n",
    "    c_index_part.rename(columns={\n",
    "        'c_index_combo': 'point_estimate',\n",
    "        'c_index_combo_ci_lower': 'ci_lower',\n",
    "        'c_index_combo_ci_upper': 'ci_upper'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Part B: Create the delta_c_index part\n",
    "    delta_c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'delta_c_index', 'delta_c_index_ci_lower', 'delta_c_index_ci_upper']].copy()\n",
    "    delta_c_index_part['metric'] = 'delta_c_index'\n",
    "    delta_c_index_part.rename(columns={\n",
    "        'delta_c_index': 'point_estimate',\n",
    "        'delta_c_index_ci_lower': 'ci_lower',\n",
    "        'delta_c_index_ci_upper': 'ci_upper'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # --- 5. Final Integration ---\n",
    "    final_df = pd.concat([c_index_part, delta_c_index_part], ignore_index=True)\n",
    "    final_df = final_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'metric', 'point_estimate', 'ci_lower', 'ci_upper']]\n",
    "\n",
    "    # --- 6. Save Results ---\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "    print(f\"Successfully processed and saved to: {output_file}\\n\")\n",
    "\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == \"__main__\":\n",
    "    BASE_INPUT_PATH = '/your path/cardiomicscore/saved/results/Cindex'\n",
    "    BASE_OUTPUT_PATH = '/your path/cardiomicscore/saved/results/Cindex/Merge'\n",
    "\n",
    "    # Define a list of all model prefixes to process\n",
    "    model_prefixes_to_process = ['glm', 'xgb', 'lgbm', 'rf', 'unweighted']\n",
    "\n",
    "    # Loop through and process each model in the list\n",
    "    for prefix in model_prefixes_to_process:\n",
    "        process_and_merge_cindex_data(prefix, BASE_INPUT_PATH, BASE_OUTPUT_PATH)\n",
    "        \n",
    "    print(\"--- All models processed. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_model_and_get_df(model_prefix, base_path):\n",
    "    \"\"\"\n",
    "    Processes the data for a single model, adds a 'model' column, \n",
    "    and returns the resulting DataFrame.\n",
    "\n",
    "    Args:\n",
    "        model_prefix (str): The prefix name of the model, e.g., 'glm', 'xgb'.\n",
    "        base_path (str): The directory where the input files are located.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with the processed data, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    # --- 1. Dynamically generate filenames based on the model prefix ---\n",
    "    summary_file = os.path.join(base_path, f'cindex_{model_prefix}_summary.csv')\n",
    "    ci_file = os.path.join(base_path, f'cindex_{model_prefix}_bootstrap_ci_summary.csv')\n",
    "\n",
    "    print(f\"--- Processing model: {model_prefix} ---\")\n",
    "\n",
    "    # --- 2. Load Data ---\n",
    "    try:\n",
    "        summary_df = pd.read_csv(summary_file)\n",
    "        ci_df = pd.read_csv(ci_file)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading files for {model_prefix}. Skipping. Details: {e}\")\n",
    "        return None # If files don't exist, return None\n",
    "    \n",
    "    print(f\"Standardizing 'baseline_model' in summary data for {model_prefix} to 'PANEL' before merging.\")\n",
    "    summary_df['baseline_model'] = 'PANEL'\n",
    "    \n",
    "    # --- 3. Merge & Reshape (Logic is unchanged) ---\n",
    "    merge_keys = ['outcome', 'baseline_model', 'comparison_model', 'n_samples']\n",
    "    ci_cols_to_merge = merge_keys + [\n",
    "        'c_index_combo_ci_lower', 'c_index_combo_ci_upper',\n",
    "        'delta_c_index_ci_lower', 'delta_c_index_ci_upper'\n",
    "    ]\n",
    "    merged_df = pd.merge(summary_df, ci_df[ci_cols_to_merge], on=merge_keys, how='inner')\n",
    "\n",
    "    c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'c_index_combo', 'c_index_combo_ci_lower', 'c_index_combo_ci_upper']].copy()\n",
    "    c_index_part['metric'] = 'c_index'\n",
    "    c_index_part.rename(columns={'c_index_combo': 'point_estimate', 'c_index_combo_ci_lower': 'ci_lower', 'c_index_combo_ci_upper': 'ci_upper'}, inplace=True)\n",
    "\n",
    "    delta_c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'delta_c_index', 'delta_c_index_ci_lower', 'delta_c_index_ci_upper']].copy()\n",
    "    delta_c_index_part['metric'] = 'delta_c_index'\n",
    "    delta_c_index_part.rename(columns={'delta_c_index': 'point_estimate', 'delta_c_index_ci_lower': 'ci_lower', 'delta_c_index_ci_upper': 'ci_upper'}, inplace=True)\n",
    "\n",
    "    final_df = pd.concat([c_index_part, delta_c_index_part], ignore_index=True)\n",
    "    \n",
    "    # --- 4. New requirement: Add the 'model' column ---\n",
    "    final_df['model'] = model_prefix\n",
    "    \n",
    "    print(f\"Finished processing for {model_prefix}.\")\n",
    "    # --- 5. Return the processed DataFrame ---\n",
    "    return final_df\n",
    "\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Define base input and output paths\n",
    "    BASE_INPUT_PATH = '/your path/cardiomicscore/saved/results/Cindex'\n",
    "    BASE_OUTPUT_PATH = '/your path/cardiomicscore/saved/results/Cindex/Merge'\n",
    "\n",
    "    # Define a list of all model prefixes to process\n",
    "    # model_prefixes_to_process = ['glm', 'xgb', 'lgbm', 'rf', 'unweighted']\n",
    "    model_prefixes_to_process = ['glm', 'xgb', 'lgbm', 'rf']\n",
    "\n",
    "    # Create an empty list to store the DataFrame from each processed model\n",
    "    all_models_dataframes = []\n",
    "\n",
    "    # Loop through and process each model in the list\n",
    "    for prefix in model_prefixes_to_process:\n",
    "        processed_df = process_model_and_get_df(prefix, BASE_INPUT_PATH)\n",
    "        if processed_df is not None:\n",
    "            all_models_dataframes.append(processed_df)\n",
    "    \n",
    "    # --- After the loop, combine all DataFrames in the list into one ---\n",
    "    if all_models_dataframes:\n",
    "        print(\"\\n--- Combining all processed models into a single file ---\")\n",
    "        combined_df = pd.concat(all_models_dataframes, ignore_index=True)\n",
    "\n",
    "        output_columns = [\n",
    "            'outcome', 'n_samples', 'baseline_model', 'comparison_model', 'model', \n",
    "            'metric', 'point_estimate', 'ci_lower', 'ci_upper'\n",
    "        ]\n",
    "        combined_df = combined_df[output_columns]\n",
    "\n",
    "        output_file = os.path.join(BASE_OUTPUT_PATH, 'cindex_all_models_final.csv')\n",
    "        os.makedirs(BASE_OUTPUT_PATH, exist_ok=True)\n",
    "        combined_df.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"Successfully combined all models and saved to:\\n{output_file}\")\n",
    "        print(\"\\nFinal Combined Data Preview:\")\n",
    "        print(combined_df.head())\n",
    "    else:\n",
    "        print(\"No data was processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single omics vs multiomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Set File Paths ---\n",
    "base_path = '/your path/cardiomicscore/saved/results/Cindex'\n",
    "summary_file = os.path.join(base_path, 'cindex_single_vs_multi_omics_summary.csv')\n",
    "ci_file = os.path.join(base_path, 'cindex_single_vs_multi_omics_bootstrap_ci_summary.csv')\n",
    "output_dir = '/your path/cardiomicscore/saved/results/Cindex/Merge'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, 'cindex_single_vs_multi_omics_final.csv')\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    summary_df = pd.read_csv(summary_file)\n",
    "    ci_df = pd.read_csv(ci_file)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found. Please check if the path is correct. {e}\")\n",
    "    exit() # Exit the script if files are not found\n",
    "\n",
    "# --- 3. Merge Data ---\n",
    "merge_keys = ['outcome', 'baseline_model', 'comparison_model', 'n_samples']\n",
    "ci_cols_to_merge = merge_keys + [\n",
    "    'c_index_combo_ci_lower', 'c_index_combo_ci_upper',\n",
    "    'delta_c_index_ci_lower', 'delta_c_index_ci_upper'\n",
    "]\n",
    "print(\"Merging the two DataFrames...\")\n",
    "merged_df = pd.merge(summary_df, ci_df[ci_cols_to_merge], on=merge_keys, how='inner')\n",
    "print(\"Data merge complete.\")\n",
    "\n",
    "\n",
    "# --- 4. Reshape Data ---\n",
    "print(\"Reshaping data into a long format...\")\n",
    "# Part A: Create the c_index part\n",
    "c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'c_index_combo', 'c_index_combo_ci_lower', 'c_index_combo_ci_upper']].copy()\n",
    "c_index_part['metric'] = 'c_index'\n",
    "c_index_part.rename(columns={\n",
    "    'c_index_combo': 'point_estimate',\n",
    "    'c_index_combo_ci_lower': 'ci_lower',\n",
    "    'c_index_combo_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# Part B: Create the delta_c_index part\n",
    "delta_c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'delta_c_index', 'delta_c_index_ci_lower', 'delta_c_index_ci_upper']].copy()\n",
    "delta_c_index_part['metric'] = 'delta_c_index'\n",
    "delta_c_index_part.rename(columns={\n",
    "    'delta_c_index': 'point_estimate',\n",
    "    'delta_c_index_ci_lower': 'ci_lower',\n",
    "    'delta_c_index_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# --- 5. Final Integration ---\n",
    "final_df = pd.concat([c_index_part, delta_c_index_part], ignore_index=True)\n",
    "final_df = final_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'metric', 'point_estimate', 'ci_lower', 'ci_upper']]\n",
    "print(\"Data reshaping complete.\")\n",
    "\n",
    "# --- 6. Save Results ---\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nProcessing complete! The consolidated file has been saved to:\\n{output_file}\")\n",
    "\n",
    "# --- Print a preview of the result ---\n",
    "print(\"\\nFinal Data Preview (first 10 rows):\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclude events occured within 2 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Set File Paths ---\n",
    "base_path = '/your path/cardiomicscore/saved/results/Cindex'\n",
    "summary_file = os.path.join(base_path, 'cindex_event_2yrs_summary.csv')\n",
    "ci_file = os.path.join(base_path, 'cindex_event_2yrs_bootstrap_ci_summary.csv')\n",
    "output_dir = '/your path/cardiomicscore/saved/results/Cindex/Merge'\n",
    "output_file = os.path.join(output_dir, 'cindex_event_2yrs_final.csv')\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    summary_df = pd.read_csv(summary_file)\n",
    "    ci_df = pd.read_csv(ci_file)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found. Please check if the path is correct. {e}\")\n",
    "    exit() # Exit the script if files are not found\n",
    "\n",
    "# --- 3. Merge Data ---\n",
    "merge_keys = ['outcome', 'baseline_model', 'comparison_model', 'n_samples']\n",
    "ci_cols_to_merge = merge_keys + [\n",
    "    'c_index_combo_ci_lower', 'c_index_combo_ci_upper',\n",
    "    'delta_c_index_ci_lower', 'delta_c_index_ci_upper'\n",
    "]\n",
    "print(\"Merging the two DataFrames...\")\n",
    "merged_df = pd.merge(summary_df, ci_df[ci_cols_to_merge], on=merge_keys, how='inner')\n",
    "print(\"Data merge complete.\")\n",
    "\n",
    "\n",
    "# --- 4. Reshape Data ---\n",
    "print(\"Reshaping data into a long format...\")\n",
    "# Part A: Create the c_index part\n",
    "c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'c_index_combo', 'c_index_combo_ci_lower', 'c_index_combo_ci_upper']].copy()\n",
    "c_index_part['metric'] = 'c_index'\n",
    "c_index_part.rename(columns={\n",
    "    'c_index_combo': 'point_estimate',\n",
    "    'c_index_combo_ci_lower': 'ci_lower',\n",
    "    'c_index_combo_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# Part B: Create the delta_c_index part\n",
    "delta_c_index_part = merged_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'delta_c_index', 'delta_c_index_ci_lower', 'delta_c_index_ci_upper']].copy()\n",
    "delta_c_index_part['metric'] = 'delta_c_index'\n",
    "delta_c_index_part.rename(columns={\n",
    "    'delta_c_index': 'point_estimate',\n",
    "    'delta_c_index_ci_lower': 'ci_lower',\n",
    "    'delta_c_index_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# --- 5. Final Integration ---\n",
    "final_df = pd.concat([c_index_part, delta_c_index_part], ignore_index=True)\n",
    "final_df = final_df[['outcome', 'n_samples', 'baseline_model', 'comparison_model', 'metric', 'point_estimate', 'ci_lower', 'ci_upper']]\n",
    "print(\"Data reshaping complete.\")\n",
    "\n",
    "# --- 6. Save Results ---\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nProcessing complete! The consolidated file has been saved to:\\n{output_file}\")\n",
    "\n",
    "# --- Print a preview of the result ---\n",
    "print(\"\\nFinal Data Preview (first 10 rows):\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-gray models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Set File Paths ---\n",
    "base_path = '/your path/cardiomicscore/saved/results/Cindex'\n",
    "output_dir = '/your path/cardiomicscore/saved/results/Cindex/Merge'\n",
    "\n",
    "# Main data file\n",
    "summary_file = os.path.join(base_path, 'cindex_competing_risk_summary.csv')\n",
    "\n",
    "# List of all Confidence Interval (CI) files to be consolidated\n",
    "ci_files = [\n",
    "    'cindex_competing_risk_bootstrap_ci_cad_stroke.csv',\n",
    "    'cindex_competing_risk_bootstrap_ci_hf_af.csv',\n",
    "    'cindex_competing_risk_bootstrap_ci_pad_vte.csv'\n",
    "]\n",
    "output_file = os.path.join(output_dir, 'cindex_competing_risk_final.csv')\n",
    "\n",
    "\n",
    "# --- 2. Load and consolidate all CI files ---\n",
    "print(\"Loading and consolidating all competing risk CI files...\")\n",
    "ci_df_list = []\n",
    "try:\n",
    "    for file_name in ci_files:\n",
    "        full_path = os.path.join(base_path, file_name)\n",
    "        df = pd.read_csv(full_path)\n",
    "        ci_df_list.append(df)\n",
    "    combined_ci_df = pd.concat(ci_df_list, ignore_index=True)\n",
    "    print(f\"Successfully consolidated {len(ci_files)} CI files.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found. Please check the CI file list and paths. {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Load main data file and merge ---\n",
    "print(\"Loading the main data file...\")\n",
    "try:\n",
    "    summary_df = pd.read_csv(summary_file)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find the summary file {summary_file}.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Merging the summary data with the CI data...\")\n",
    "merge_keys = ['outcome', 'baseline_model', 'comparison_model', 'n_samples']\n",
    "ci_cols_to_merge = merge_keys + [\n",
    "    'c_index_combo_ci_lower', 'c_index_combo_ci_upper',\n",
    "    'delta_c_index_ci_lower', 'delta_c_index_ci_upper'\n",
    "]\n",
    "merged_df = pd.merge(summary_df, combined_ci_df[ci_cols_to_merge], on=merge_keys, how='inner')\n",
    "print(\"Data merge complete.\")\n",
    "\n",
    "\n",
    "# --- 4. Reshape Data (same logic as before) ---\n",
    "print(\"Reshaping data into a long format...\")\n",
    "\n",
    "# Part A: c_index part\n",
    "c_index_cols = merge_keys + ['c_index_combo', 'c_index_combo_ci_lower', 'c_index_combo_ci_upper']\n",
    "c_index_part = merged_df[c_index_cols].copy()\n",
    "c_index_part['metric'] = 'c_index'\n",
    "c_index_part.rename(columns={\n",
    "    'c_index_combo': 'point_estimate',\n",
    "    'c_index_combo_ci_lower': 'ci_lower',\n",
    "    'c_index_combo_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "# Part B: delta_c_index part\n",
    "delta_c_index_cols = merge_keys + ['delta_c_index', 'delta_c_index_ci_lower', 'delta_c_index_ci_upper']\n",
    "delta_c_index_part = merged_df[delta_c_index_cols].copy()\n",
    "delta_c_index_part['metric'] = 'delta_c_index'\n",
    "delta_c_index_part.rename(columns={\n",
    "    'delta_c_index': 'point_estimate',\n",
    "    'delta_c_index_ci_lower': 'ci_lower',\n",
    "    'delta_c_index_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "\n",
    "# --- 5. Final Integration ---\n",
    "final_df = pd.concat([c_index_part, delta_c_index_part], ignore_index=True)\n",
    "output_columns = [\n",
    "    'outcome', 'n_samples', 'baseline_model', \n",
    "    'comparison_model', 'metric', 'point_estimate', 'ci_lower', 'ci_upper'\n",
    "]\n",
    "final_df = final_df[output_columns]\n",
    "print(\"Data reshaping complete.\")\n",
    "\n",
    "\n",
    "# --- 6. Save Results ---\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nProcessing complete! The consolidated file has been saved to:\\n{output_file}\")\n",
    "\n",
    "# --- Print a preview of the result ---\n",
    "print(\"\\nFinal Data Preview (first 10 rows):\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geographic test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Set File Paths ---\n",
    "base_path = '/your path/cardiomicscore/saved/results/Cindex'\n",
    "output_dir = '/your path/cardiomicscore/saved/results/Cindex/Merge'\n",
    "summary_file = os.path.join(base_path, 'cindex_train_val_internal_test_summary.csv')\n",
    "ci_file = os.path.join(base_path, 'cindex_train_val_internal_test_bootstrap_ci_summary.csv')\n",
    "output_file = os.path.join(output_dir, 'cindex_train_val_test_final.csv')\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    summary_df = pd.read_csv(summary_file)\n",
    "    ci_df = pd.read_csv(ci_file)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found. Please check if the paths are correct. {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Merge Data ---\n",
    "print(\"Merging the two DataFrames...\")\n",
    "merge_keys = ['data_split', 'outcome', 'model', 'n_samples', 'n_events']\n",
    "ci_cols_to_merge = merge_keys + ['c_index_ci_lower', 'c_index_ci_upper']\n",
    "merged_df = pd.merge(summary_df, ci_df[ci_cols_to_merge], on=merge_keys, how='inner')\n",
    "print(\"Data merge complete.\")\n",
    "\n",
    "\n",
    "# --- 4. Format and Reshape Data ---\n",
    "print(\"Formatting data to match the output structure...\")\n",
    "final_df = pd.DataFrame()\n",
    "final_df['data_split'] = merged_df['data_split']\n",
    "final_df['outcome'] = merged_df['outcome']\n",
    "final_df['n_samples'] = merged_df['n_samples']\n",
    "final_df['comparison_model'] = merged_df['model']\n",
    "\n",
    "final_df['metric'] = 'c_index'\n",
    "final_df['point_estimate'] = merged_df['c_index']\n",
    "final_df['ci_lower'] = merged_df['c_index_ci_lower']\n",
    "final_df['ci_upper'] = merged_df['c_index_ci_upper']\n",
    "\n",
    "output_columns = ['data_split', 'outcome', 'n_samples', 'comparison_model', 'metric', 'point_estimate', 'ci_lower', 'ci_upper']\n",
    "final_df = final_df[output_columns]\n",
    "print(\"Data formatting complete.\")\n",
    "\n",
    "# --- 5. Save Results ---\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nProcessing complete! The consolidated file has been saved to:\\n{output_file}\")\n",
    "\n",
    "# --- Print a preview of the result ---\n",
    "print(\"\\nFinal Data Preview (first 10 rows):\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Set File Paths ---\n",
    "base_path = '/your path/cardiomicscore/saved/results/Cindex'\n",
    "output_dir = '/your path/cardiomicscore/saved/results/Cindex/Merge'\n",
    "\n",
    "# Define input and output filenames\n",
    "input_file = os.path.join(base_path, 'clinical_scores_cindex_summary.csv')\n",
    "output_file = os.path.join(output_dir, 'clinical_scores_final.csv')\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "print(f\"Loading file: {input_file}...\")\n",
    "try:\n",
    "    df = pd.read_csv(input_file)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found. Please check if the path is correct. {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Format Data ---\n",
    "print(\"Formatting the data...\")\n",
    "df.rename(columns={\n",
    "    'predictor': 'comparison_model',\n",
    "    'cindex': 'point_estimate',\n",
    "    'cindex_ci_lower': 'ci_lower',\n",
    "    'cindex_ci_upper': 'ci_upper'\n",
    "}, inplace=True)\n",
    "df = df.assign(metric='c_index')\n",
    "\n",
    "output_columns = [\n",
    "    'outcome', \n",
    "    'comparison_model', \n",
    "    'metric', \n",
    "    'point_estimate', \n",
    "    'ci_lower', \n",
    "    'ci_upper'\n",
    "]\n",
    "final_df = df[output_columns]\n",
    "print(\"Data formatting complete.\")\n",
    "\n",
    "# --- 4. Save Results ---\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nProcessing complete! The formatted file has been saved to:\\n{output_file}\")\n",
    "\n",
    "# --- Print a preview of the result ---\n",
    "print(\"\\nFinal Data Preview:\")\n",
    "print(final_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omicscvd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
