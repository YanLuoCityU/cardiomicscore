{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OmicsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\"\"\"\n",
    "Reads score files from multiple runs, calculates the average score for each sample (eid),\n",
    "displays a verification sample, and saves the final averaged scores.\n",
    "\"\"\"\n",
    "# 1. Define paths\n",
    "# Base path where the SEED directories (1234, 1235, etc.) are located\n",
    "base_path = \"/your path/cardiomicscore/saved/results/Scores/OmicsNet\"\n",
    "\n",
    "# Output path for the final averaged results\n",
    "output_path = os.path.join(base_path, \"Final\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "print(f\"Results will be saved to: {output_path}\")\n",
    "\n",
    "# 2. Automatically discover SEED directories and score files\n",
    "try:\n",
    "    # Find all directories that are named like a number (our SEEDs)\n",
    "    seed_dirs = sorted([d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d)) and d.isdigit()])\n",
    "    if not seed_dirs:\n",
    "        raise FileNotFoundError(\"No valid SEED directories found in the base path.\")\n",
    "    \n",
    "    print(f\"Found {len(seed_dirs)} SEED runs: {seed_dirs}\")\n",
    "\n",
    "    # Get the list of score files to process from the first SEED directory\n",
    "    first_seed_path = os.path.join(base_path, seed_dirs[0])\n",
    "    score_files_to_process = [f for f in os.listdir(first_seed_path) if f.endswith('.csv')]\n",
    "    if not score_files_to_process:\n",
    "        raise FileNotFoundError(f\"No .csv files found in directory: {first_seed_path}\")\n",
    "        \n",
    "    print(f\"Found {len(score_files_to_process)} unique score files to process.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# 3. Loop through each unique score file name\n",
    "for score_filename in score_files_to_process:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Processing score file: {score_filename}\")\n",
    "\n",
    "    list_of_dfs = []\n",
    "    # Collect the full path for the current file from each SEED directory\n",
    "    for seed in seed_dirs:\n",
    "        file_path = os.path.join(base_path, seed, score_filename)\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                list_of_dfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not read file {file_path}. Error: {e}. Skipping.\")\n",
    "        else:\n",
    "            print(f\"Warning: File not found and will be skipped: {file_path}\")\n",
    "\n",
    "    if not list_of_dfs:\n",
    "        print(f\"No valid data found for {score_filename}. Skipping to next file.\")\n",
    "        continue\n",
    "        \n",
    "    # 4. Core averaging logic:\n",
    "    # Concatenate all dataframes, set 'eid' as the index,\n",
    "    # then group by 'eid' and calculate the mean. This is the most robust method.\n",
    "    combined_df = pd.concat([df.set_index('eid') for df in list_of_dfs])\n",
    "    final_avg_df = combined_df.groupby('eid').mean().reset_index()\n",
    "    \n",
    "    print(f\"Successfully averaged {len(list_of_dfs)} files. Resulting shape: {final_avg_df.shape}\")\n",
    "\n",
    "    # 5. Verification step for 10 random samples\n",
    "    print(\"\\n--- Verification for 10 random samples (eids) ---\")\n",
    "    \n",
    "    # Get the list of score columns (all columns except 'eid')\n",
    "    score_columns = [col for col in final_avg_df.columns if col != 'eid']\n",
    "    if not score_columns:\n",
    "        print(\"No score columns found for verification. Skipping.\")\n",
    "    else:\n",
    "        # We will use the first score column for the verification display\n",
    "        verification_col = score_columns[0]\n",
    "        print(f\"Showing verification for the first score column: '{verification_col}'\")\n",
    "        \n",
    "        # Get 10 random eids from the final result\n",
    "        sample_eids = random.sample(final_avg_df['eid'].tolist(), min(10, len(final_avg_df)))\n",
    "        \n",
    "        verification_data = []\n",
    "        for eid in sample_eids:\n",
    "            row_data = {'eid': eid}\n",
    "            # Get score from each individual run\n",
    "            for i, df in enumerate(list_of_dfs):\n",
    "                seed_name = seed_dirs[i]\n",
    "                # Find the score for the specific eid in the original dataframe\n",
    "                score = df.loc[df['eid'] == eid, verification_col].values[0]\n",
    "                row_data[f'Run_{seed_name}_Score'] = score\n",
    "            \n",
    "            # Get the final averaged score\n",
    "            final_score = final_avg_df.loc[final_avg_df['eid'] == eid, verification_col].values[0]\n",
    "            row_data['Final_Avg_Score'] = final_score\n",
    "            verification_data.append(row_data)\n",
    "\n",
    "        verification_df = pd.DataFrame(verification_data)\n",
    "        print(verification_df.to_string())\n",
    "\n",
    "    # 6. Save the final averaged scores to a new CSV file\n",
    "    output_file_path = os.path.join(output_path, score_filename)\n",
    "    try:\n",
    "        final_avg_df.to_csv(output_file_path, index=False)\n",
    "        print(f\"\\nSuccessfully saved final average scores to:\\n{output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving file to {output_file_path}. Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"All processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OmicsNet_Unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\"\"\"\n",
    "Reads score files from multiple runs, calculates the average score for each sample (eid),\n",
    "displays a verification sample, and saves the final averaged scores.\n",
    "\"\"\"\n",
    "# 1. Define paths\n",
    "# Base path where the SEED directories (1234, 1235, etc.) are located\n",
    "base_path = \"/your path/cardiomicscore/saved/results/Scores/OmicsNet_Unweighted\"\n",
    "\n",
    "# Output path for the final averaged results\n",
    "output_path = os.path.join(base_path, \"Final\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "print(f\"Results will be saved to: {output_path}\")\n",
    "\n",
    "# 2. Automatically discover SEED directories and score files\n",
    "try:\n",
    "    # Find all directories that are named like a number (our SEEDs)\n",
    "    seed_dirs = sorted([d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d)) and d.isdigit()])\n",
    "    if not seed_dirs:\n",
    "        raise FileNotFoundError(\"No valid SEED directories found in the base path.\")\n",
    "    \n",
    "    print(f\"Found {len(seed_dirs)} SEED runs: {seed_dirs}\")\n",
    "\n",
    "    # Get the list of score files to process from the first SEED directory\n",
    "    first_seed_path = os.path.join(base_path, seed_dirs[0])\n",
    "    score_files_to_process = [f for f in os.listdir(first_seed_path) if f.endswith('.csv')]\n",
    "    if not score_files_to_process:\n",
    "        raise FileNotFoundError(f\"No .csv files found in directory: {first_seed_path}\")\n",
    "        \n",
    "    print(f\"Found {len(score_files_to_process)} unique score files to process.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# 3. Loop through each unique score file name\n",
    "for score_filename in score_files_to_process:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Processing score file: {score_filename}\")\n",
    "\n",
    "    list_of_dfs = []\n",
    "    # Collect the full path for the current file from each SEED directory\n",
    "    for seed in seed_dirs:\n",
    "        file_path = os.path.join(base_path, seed, score_filename)\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                list_of_dfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not read file {file_path}. Error: {e}. Skipping.\")\n",
    "        else:\n",
    "            print(f\"Warning: File not found and will be skipped: {file_path}\")\n",
    "\n",
    "    if not list_of_dfs:\n",
    "        print(f\"No valid data found for {score_filename}. Skipping to next file.\")\n",
    "        continue\n",
    "        \n",
    "    # 4. Core averaging logic:\n",
    "    # Concatenate all dataframes, set 'eid' as the index,\n",
    "    # then group by 'eid' and calculate the mean. This is the most robust method.\n",
    "    combined_df = pd.concat([df.set_index('eid') for df in list_of_dfs])\n",
    "    final_avg_df = combined_df.groupby('eid').mean().reset_index()\n",
    "    \n",
    "    print(f\"Successfully averaged {len(list_of_dfs)} files. Resulting shape: {final_avg_df.shape}\")\n",
    "\n",
    "    # 5. Verification step for 10 random samples\n",
    "    print(\"\\n--- Verification for 10 random samples (eids) ---\")\n",
    "    \n",
    "    # Get the list of score columns (all columns except 'eid')\n",
    "    score_columns = [col for col in final_avg_df.columns if col != 'eid']\n",
    "    if not score_columns:\n",
    "        print(\"No score columns found for verification. Skipping.\")\n",
    "    else:\n",
    "        # We will use the first score column for the verification display\n",
    "        verification_col = score_columns[0]\n",
    "        print(f\"Showing verification for the first score column: '{verification_col}'\")\n",
    "        \n",
    "        # Get 10 random eids from the final result\n",
    "        sample_eids = random.sample(final_avg_df['eid'].tolist(), min(10, len(final_avg_df)))\n",
    "        \n",
    "        verification_data = []\n",
    "        for eid in sample_eids:\n",
    "            row_data = {'eid': eid}\n",
    "            # Get score from each individual run\n",
    "            for i, df in enumerate(list_of_dfs):\n",
    "                seed_name = seed_dirs[i]\n",
    "                # Find the score for the specific eid in the original dataframe\n",
    "                score = df.loc[df['eid'] == eid, verification_col].values[0]\n",
    "                row_data[f'Run_{seed_name}_Score'] = score\n",
    "            \n",
    "            # Get the final averaged score\n",
    "            final_score = final_avg_df.loc[final_avg_df['eid'] == eid, verification_col].values[0]\n",
    "            row_data['Final_Avg_Score'] = final_score\n",
    "            verification_data.append(row_data)\n",
    "\n",
    "        verification_df = pd.DataFrame(verification_data)\n",
    "        print(verification_df.to_string())\n",
    "\n",
    "    # 6. Save the final averaged scores to a new CSV file\n",
    "    output_file_path = os.path.join(output_path, score_filename)\n",
    "    try:\n",
    "        final_avg_df.to_csv(output_file_path, index=False)\n",
    "        print(f\"\\nSuccessfully saved final average scores to:\\n{output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving file to {output_file_path}. Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"All processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omicscvd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
